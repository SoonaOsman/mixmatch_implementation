{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Soona_mixmatch_implementation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCMhSD0BlACp"
      },
      "source": [
        "import torch \n",
        "import numpy as np\n",
        "import imgaug.augmenters as iaa"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5ItvLlasTZT"
      },
      "source": [
        "def augmentation(images):\n",
        "    seq = iaa.Sequential([\n",
        "        iaa.Crop(px=(0, 16)),\n",
        "        iaa.Fliplr(0.5),\n",
        "        iaa.GaussianBlur(sigma=(0, 3.0)),\n",
        "        iaa.Flipud(0.2),\n",
        "    ])\n",
        "    def augment():\n",
        "        return seq.augment(images.transpose(0, 2, 3, 1)).transpose(0, 2, 3, 1)\n",
        "    return augment"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goq8ydrGXMQW"
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "mean=[0.485, 0.456, 0.406]\n",
        "std=[0.229, 0.224, 0.225]\n",
        "normalize = transforms.Normalize(mean=mean, std=std)\n",
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.RandomResizedCrop(400),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.ToTensor(),normalize])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duCP4oRjnkYJ"
      },
      "source": [
        "def label_guessing(model, u_aug, k):\n",
        "  return sum(map(lambda i: model(i), u_aug)) / K"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw-KA5Dmn4RT"
      },
      "source": [
        "def Sharpening(p,T):\n",
        "  return p**(1/T) / p**(1/T).sum(axis=1, keepdims=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ziUgPZzoHOM"
      },
      "source": [
        "def MixUp(x1,p1,x2,p2,alpha):\n",
        "  lamda = np.random.beta(alpha, alpha) \n",
        "  lamda_h = np.maximum(lamda, 1-lamda)\n",
        "  x = lamda_h * x1 + (1 - lamda_h) * x2\n",
        "  p = lamda_h * p1 + (1 - lamda_h) * p2\n",
        "  return x,p"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ll4JeOKToneV"
      },
      "source": [
        "def mixmatch(model, x, p, u,augmentation, T=0.5, K=2, alpha=0.75):\n",
        "  batch_size = x.shape[0]\n",
        "  xb = augmentation(x)\n",
        "  ub = [augmentation(u) for _ in range(K)]\n",
        "  xb = x\n",
        "  ub = [u for _ in range(K)]\n",
        "  qb_h = label_guessing(model, ub, K)\n",
        "  qb = Sharpening(qb_h,T)\n",
        "  U_h = np.concatenate(ub, axis=0)\n",
        "  U_hq = np.concatenate([qb for _ in range(K)], axis=0)\n",
        "  indices = np.random.shuffle(np.arange(len(xb) + len(U_h)))\n",
        "  W_ux = np.concatenate([U_h, xb], axis=0)[indices]\n",
        "  W_qp = np.concatenate([qb, p], axis=0)[indices]\n",
        "  X_, p = mixup(xb, p, W_ux[:len(xb)], W_qp[:len(xb)], alpha)\n",
        "  U_, q = mixup(U_h, U_hq, W_ux[len(xb):], W_qp[len(xb):], alpha)\n",
        "  return X_, U_, p, q"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GrEkGtioZGS"
      },
      "source": [
        "def ssLoss( p, pred_x, q, pred_u, lamda_u=100):\n",
        "  l_x= torch.nn.CrossEntropyLoss(p,pred_x) \n",
        "  l_u= torch.nn.MSELoss(q,pred_u)\n",
        "  return l_x + lamda_u*l_u"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI3o_gt9i_hp"
      },
      "source": [
        "import torchvision.models as models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrMsadtXDnsF"
      },
      "source": [
        "wide_resnet_model=models.wide_resnet50_2(pretrained=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF_42GJMiuea"
      },
      "source": [
        "transform = transforms.Compose( \n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5Jl9rGsCNFW",
        "outputId": "6facf82f-d41a-472c-afed-9ae28780e4dc"
      },
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                        download=True, transform=train_transforms)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cE6p-qqbHC58"
      },
      "source": [
        "# X_train = np.array(trainset.data)\n",
        "# y_train = np.array(trainset.targets)\n",
        "X_train =trainset.data\n",
        "y_train =trainset.targets\n",
        "\n",
        "# Train set / Validation set split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=1,\n",
        "                                                          shuffle=True, stratify=y_train)\n",
        "\n",
        "# Train unsupervised / Train supervised split\n",
        "X_train, X_u_train, y_train, y_u_train = train_test_split(X_train, y_train, test_size=0.7, random_state=1,\n",
        "                                                          shuffle=True, stratify=y_train)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDHmpEZ5HONO"
      },
      "source": [
        "data = zip(X_train, X_u_train, y_train)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krlgy8BWFPM2"
      },
      "source": [
        "optimizer = torch.optim.Adam(wide_resnet_model.parameters(), weight_decay=0.0004 ) \n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iR0AyBYan2Zj"
      },
      "source": [
        "def to_torch(*args, device='cuda'):\n",
        "    convert_fn = lambda x: torch.from_numpy(x).to(device)\n",
        "    return list(map(convert_fn, args))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZxGiGdvHyEB"
      },
      "source": [
        "def train(model ,data,optimizer,num_epochs):\n",
        "  model.train()\n",
        "  model.to(device)\n",
        "  for epoch in range(1):\n",
        "    for x,u,p in data:\n",
        "      X, U, p, q = mixmatch(model,x,p,u,augmentation)\n",
        "      print(X.shape, U.shape)\n",
        "      X, U, p, q = to_torch(x, u, p, q, device=device)\n",
        "      X_pred= model(X)\n",
        "      U_pred = model(U)\n",
        "      loss = ssLoss(p,X_pred, q, U_pred)\n",
        "      print(epoch,loss.item())\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      \n",
        "        "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xn72-8MIH7Kn"
      },
      "source": [
        "train(wide_resnet_model,data,optimizer,100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyT2btOrjpCg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}